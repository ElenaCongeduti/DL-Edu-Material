{"metadata":{"colab":{"provenance":[{"file_id":"1vu_pIE6wcHStyvgH4brKCZhPr_ErtcCp","timestamp":1696084673558}]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Lab 4**\n\nTI3155TU Deep Learning (2024 - 2025)\n\nAdapted by Elena Congeduti from TU Delft CS4240 Deep Learning course\n","metadata":{"id":"nVCW6YSA4jSH"}},{"cell_type":"markdown","source":"# Instructions\n**For this lab, we recommend working on Google Colab as it provides direct support for the TensorBoard library. To do this, select the 'Open in Colab' option from the notebook's homepage menu.**\n\nAlternatively, you can work locally. In this case, you will need to set up your own virtual environment. Check the Lab Instructions in [Learning Material](https://brightspace.tudelft.nl/d2l/le/content/682797/Home?itemIdentifier=D2L.LE.Content.ContentObject.ModuleCO-3812764) on Brightspace for detailed information on the virtual environment configuration.\n\nThese labs include programming exercises and insight questions. Follow the instructions in the notebook. Fill in the text blocks to answer the questions and write your own code to solve the programming tasks within the designated part of the code blocks:\n\n```python\n#############################################################################\n#                           START OF YOUR CODE                              #\n#############################################################################\n\n\n#############################################################################\n#                            END OF YOUR CODE                               #\n#############################################################################\n```\n\nSolutions will be shared the week after the lab is published. Note that these labs are designed for practice and are therefore **ungraded**.\n\n","metadata":{"id":"7rSnXZSgqpfk"}},{"cell_type":"code","source":"# Setup\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import datasets, transforms\n\n#Only if you run it on Kaggle\n#!pip install torchsummary\n\nimport math\nfrom torchsummary import summary\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Additional Setup for MNIST-1D\n!git clone https://github.com/greydanus/mnist1d\n!mv mnist1d/mnist1d/* mnist1d/\n\nimport mnist1d\nfrom mnist1d.data import get_templates, get_dataset_args, get_dataset\nfrom mnist1d.utils import set_seed, plot_signals, ObjectView, from_pickle\n\n# Additional Setup to use Tensorboard\n!pip install -q tensorflow\n\n%load_ext tensorboard","metadata":{"id":"gIvAOzFjhtw6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1 Exponentially Weighted Moving Average (EWMA)\n\nExponentially weighted moving average can be used to smooth out noisy data. It's a very versatile tool that has applications not only in machine learning, but also signal processing or finance.\n\nThe formula for EWMA is very simple. Note that the formula is recursive, meaning the current iteration uses the outcome of previous iterations\n\n$$S^t=\\rho S^{t-1} + (1-\\rho)y^t$$\n\nThe $\\rho$ parameter determines the strength of the smoothing, or how much of the output value will be determined by the average of previous values and how much by the current value.\n\n","metadata":{"id":"7YX7M-1siKSl"}},{"cell_type":"markdown","source":"****\n**Question 1.1:** Where have we already seen this type of recursive formula?\n","metadata":{"id":"_kAS1p4IJNFf"}},{"cell_type":"markdown","source":"<font color='green'> Write your answer here\n</font>\n****","metadata":{"id":"w1yC3WHZJZZC"}},{"cell_type":"markdown","source":"\nAlthough EWMA is by far not the only way to smooth a series of (multi dimensional) data points it is very flexible and memory efficient since it can take an arbitrary number of input values and only requires to additionally store the previously calculated averages.\n\nEWMA forms the basis of all optimizers that you'll implement today.\n\nIn this first exercise you will implement EWMA to smooth out a series of noisy data. Run the cell below to create the noisy data. Keep the data length, wave length and noise level at their preassigned value for now. Once you have implemented your own version of EWMA you can come back and see what changes if you adjust these parameters.","metadata":{"id":"J3xb4mqMJMOB"}},{"cell_type":"code","source":"## Generate some noisy data\nn = 400 # Length of the data\nwl = 2 # Wavelength of underlying data\nnoise_level = 2 # Strength of noise\n\nx = np.linspace(0,wl*math.pi,n)\ndata_clean = np.sin(x+2)+ noise_level\ndata = data_clean + (np.random.random(n)-0.5)*noise_level\n\nplt.scatter(x, data, s=3)\nplt.plot(x, data_clean, 'orange', linewidth=3)","metadata":{"id":"_dVhMSYfdM4s","executionInfo":{"status":"ok","timestamp":1696682511294,"user_tz":-120,"elapsed":737,"user":{"displayName":"Elena Congeduti","userId":"06963343184623262712"}},"outputId":"cd5f44e8-991c-41ab-e3d6-02fd2d2dd840","_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n**Task 1.2:** Implement EWMA update as `s_cur` and add the bias correction to `s_cur_bc`.\n****","metadata":{"id":"uE2Lqly-KQxh"}},{"cell_type":"code","source":"rho = 0.95 # Rho value for smoothing\n\ns_prev = 0 # Initial value ewma value\n\n# Empty arrays to hold the smoothed data\newma, ewma_bias_corr = np.empty(0), np.empty(0)\n\nfor i,y in enumerate(data):\n\n    # Variables to store smoothed data point\n    s_cur = 0\n    s_cur_bc = 0\n\n    #############################################################################\n    #                            START OF YOUR CODE                             #\n    #############################################################################\n\n    #############################################################################\n    #                            END OF YOUR CODE                               #\n    #############################################################################\n\n    # Append new smoothed value to array\n    ewma = np.append(ewma,s_cur)\n    ewma_bias_corr = np.append(ewma_bias_corr,s_cur_bc)\n\n    s_prev = s_cur\n\nplt.scatter(x, data, s=3)\nplt.plot(x, ewma, 'r--', linewidth=3)\nplt.plot(x, ewma_bias_corr, 'g--', linewidth=3)\nplt.plot(x, data_clean, 'orange', linewidth=3)","metadata":{"id":"uj8XtVdKiuf7","_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n**Question 1.3:** What do the curves in this plot represent? Can we conclude something on the effect of ewma?\n","metadata":{"id":"h8Qr0XZ6LC2_"}},{"cell_type":"markdown","source":"<font color='green'> Write your answer here </font>\n\n****","metadata":{"id":"nQ0QrWFGLdta"}},{"cell_type":"markdown","source":"# 2 Optimization Algorithms\n\nNow that you have seen what an EWMA looks like in 1D we're ready to use it to build some optimizers for a 2D case and look at some nice visualizations.\n\nYou'll get the opportunity to explore three different types of optimizers: Momentum, RMSProp and Adam. There are multiple others optimizers available, but these three should give you a good intuition of what an optimizer does and a solid base to understand other optimizers.\n\nWell use a quadratic function (inspired by [this]( https://xavierbourretsicotte.github.io/Intro_optimization.html) tutorial) as a toy example to show the effects of different optimizers. We'll use the derivative of that function to calculate our gradients.\n\nNote that this is only a toy example and not a complete representation of stochastic gradient descent. Since we're using a function and it's derivative, we do know the exact distribution of our data. In a real world example we would not know it and would use batches of our training examples to approximate the gradient.\n\nIn the following exercises you will be asked to implement three optimizers and see how they compare.\n\nIn the next cell we will define the two methods that define the quadratic function and it's derivative to calculate the gradients as well as two helper functions to help us visualize the function and the training.\n\nUsing the ```setup_figure``` function we can plot the surface and contours of the quadratic functions we defined. You can always rerun this cell to reset your plot.\n","metadata":{"id":"bI3SdSD5oo0G"}},{"cell_type":"code","source":"def f(x,y):\n    '''A simple quadratic function'''\n    return .01*x**2 + .1*y**2\n\ndef Grad_f(x,y):\n    '''Gradients of function f'''\n    g1 = 2*.01*x\n    g2 = 2*.1*y\n    return np.array([g1,g2])\n\n","metadata":{"id":"1zFT6woBOKVL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\ndef setup_figure(f):\n    '''Creates a Surface and a contour plot of the function f'''\n    x = np.linspace(-3, 3, 250)\n    y = np.linspace(-3, 3, 250)\n    X, Y = np.meshgrid(x, y)\n    Z = f(X, Y)\n\n    fig,(ax1,ax2) = plt.subplots(1,2,figsize = (16,8))\n\n    # Surface plot\n    ax1 = plt.subplot(121, projection='3d')\n    ax1.plot_surface(X, Y, Z, rstride=5, cstride=5, cmap='jet', alpha=.4, edgecolor='none')\n    ax1.set_title('f(x,y) = .01x^2 + .1y^2')\n\n    ax1.view_init(65, 340)\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('y')\n\n    # Contour plot\n    ax2 = plt.subplot(122)\n    ax2.contour(X, Y, Z, 50, cmap='jet')\n    ax2.set_title('Gradient Descent')\n\n    return fig,(ax1,ax2)\n\ndef add_line(iter_x,iter_y,fig,ax1,ax2,color='r'):\n    '''Adds lines to the provided figure'''\n\n    # Angles needed for quiver plot\n    anglesx = iter_x[1:] - iter_x[:-1]\n    anglesy = iter_y[1:] - iter_y[:-1]\n\n    ax1.plot(iter_x, iter_y, f(iter_x,iter_y), color=color, marker='*', alpha=.4)\n\n    ax2.scatter(iter_x,iter_y,color = color, marker='*')\n    ax2.quiver(iter_x[:-1], iter_y[:-1], anglesx, anglesy, scale_units='xy',\n               angles='xy', scale=1, color=color, alpha=.3)\n    return fig, (ax1, ax2)\n\n# Get figure and axis and plot to show\nfig, axs = setup_figure(f)","metadata":{"id":"7jYcYP4KNDNs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n**Question 2.1:** In our context, what do $x$, $y$ and $f$ represent?","metadata":{"id":"lP1lmYv_ZbDd"}},{"cell_type":"markdown","source":"<font color='green'> Write your answer here </font>\n\n****","metadata":{"id":"avmdzvozZlic"}},{"cell_type":"markdown","source":"Next we define another helper function for our gradient descent. Only the first three arguments of the test_optimizer function are important to you, the rest you can ignore.\n\nThis function is written in a way that it accepts a Python function as the  ```optimizer``` argument. In the following exercises you will define those functions to implement the Momentum, RMSProp and Adam optimizer.\n\nFor the first iterations keep the learning rate and other optimizer parameters at their predefined values. Once you have implemented all optimizers feel free to explore how different parameter values influence different optimizers.","metadata":{"id":"8U6UosG1OKVM"}},{"cell_type":"code","source":"def test_optimizer(optimizer, rhos, learning_rate=0.00125,\n                   starting_point=(-2,-2), nMax=10000, epsilon=0.0001,\n                   Grad = Grad_f):\n    \"\"\"\n    Tester function for optimization algorithms. Performs gradient descent using\n    the provided Gradient until error < epsilon is reached.\n\n    Args:\n        optimizer: Optimization algorithm.\n        rhos: Hyperparameters used in some optimization algorithms.\n        learning_rate: Optimization step size.\n        starting_point: Initialization point of optimization parameters.\n        nMax: Maximum number of iterations to perform.\n        epsilon: Stop optimization if error < epsilon.\n        Grad: Gradient of quadratic function.\n    \"\"\"\n\n    # Starting points\n    x, y = starting_point\n\n    # Initialization\n    i = 0\n    iter_x, iter_y, iter_count = np.empty(0), np.empty(0), np.empty(0)\n    error = 10\n    X = np.array([x,y])\n\n    # Cache for previous values of optimizers\n    prev_vals = np.zeros_like(rhos)\n\n    # Looping as long as error is greater than epsilon\n    while np.linalg.norm(error) > epsilon and i < nMax:\n        i += 1\n        iter_x = np.append(iter_x, x)\n        iter_y = np.append(iter_y, y)\n        iter_count = np.append(iter_count, i)\n\n        X_prev = X\n\n        # Perform optimization step\n        X, prev_vals = optimizer(X, rhos, learning_rate, prev_vals, i)\n\n        # Calculate error\n        error = X - X_prev\n        x,y = X[0], X[1]\n\n    return iter_x, iter_y\n","metadata":{"id":"-HnyxwwjOKVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 Stochastic Gradient Descent (SGD)\n\nThe simplest form of an optimizer is SGD. It will always follow the gradient. Although this can lead to some good results, it requires some careful tuning of the learning rate to make sure the steps it takes are large enough to reach a minimum in appropriate time and not overshoot its target.\n\nThe following cell shows how the gradient update is implemented in gradient descent.","metadata":{"id":"So25hF4QOKVU"}},{"cell_type":"code","source":"def vanilla_gd(X, rhos, learning_rate, prev_value, index, Grad=Grad_f):\n    \"\"\"\n    Vanilla gradient descent optimization step.\n\n    Args:\n        X: Current value of objective function.\n        rhos: Not used.\n        learning_rate: Optimization step size.\n        prev_value: Not used.\n        index: Not used.\n        Grad: Gradient of quadratic function.\n    \"\"\"\n    gradient = Grad(*X)\n\n    X = X - learning_rate * gradient\n\n    return X, 0\n","metadata":{"id":"BXWz4m5NOKVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n**Question 2.2:** Try to change the learning rate. Do you get different SGD trajectories for larger or smaller values?\n****","metadata":{"id":"giCL8VijUamx"}},{"cell_type":"code","source":"# Optimization settings\nlr = 0.1\nrho = None # rho is not used in gradient descent\n\n# Run optimization\nx_gd, y_gd = test_optimizer(vanilla_gd, rho, lr)\n\n# Reset the image\nplt.ioff()\nfig, axs = setup_figure(f)\n\n# Plot optimization trajectory\nadd_line(x_gd, y_gd, fig, *axs, color='r')\n\n# Show SGD trajectory\nfig","metadata":{"id":"-MsW-O7LUw0H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Momentum\n\nMomentum is simply EWMA applied to gradient descent. It helps smoothen the gradient updates by incorporating earlier gradient steps. This is especially handy in case the SGD is overshooting the minimum due to a too high learning rate.\nIn case of overshooting, the gradient will point in (nearly opposite directions) after each update, by averaging over multiple gradients this will get cancelled out.\n\nThe formula for a gradient update with momentum is:\n\n$$v_i=\\rho v_{i-1}+(1-\\rho)\\nabla_{\\theta}$$\n\n$$\\theta^{\\prime}=\\theta-\\epsilon v_i$$\n\n\n","metadata":{"id":"c6ZxdR4OOKVU"}},{"cell_type":"markdown","source":"****\n**Task 2.3:** Complete the Momentum gradient update with the update step for  `v` and `X`.\n****","metadata":{"id":"adHMTdz8ZGmW"}},{"cell_type":"code","source":"def momentum(X, rho, learning_rate, prev_value, index, Grad=Grad_f):\n    \"\"\"\n    Gradient descent with momentum optimization step.\n\n    Args:\n        X: Current value of objective function.\n        rhos: Optimization hyperparameter - see formula above.\n        learning_rate: Optimization step size.\n        prev_value: Momentum parameter from previous iteration.\n        index: Not used.\n        Grad: Gradient of quadratic function.\n    \"\"\"\n    gradient = Grad(*X) # Gradient of current values\n    v = 0               # Momentum parameter\n    v_prev = prev_value # Momentum parameter from previous iteration\n\n    #############################################################################\n    #                           START OF YOUR CODE                              #\n    #############################################################################\n\n    #############################################################################\n    #                            END OF YOUR CODE                               #\n    #############################################################################\n\n    return X, v\n\n# Optimization settings\nlr = 0.1\nrho = 0.9\n\n# Run optimization\nres_mom = test_optimizer(momentum, rho, lr)\n\n# Plot optimization trajectory\nadd_line(*res_mom, fig, *axs, color='b')\n\n# Show figure\nfig","metadata":{"id":"0Viezio7OKVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 RMSProp\n\nRMSProp also uses EWMA for previous versions of the gradient update. However, unlike momentum it does not use this average to update the gradient directly but to scale the learning rate of update. By doing this it is able to take larger steps towards the beginning of the learning process and smaller steps towards the end.\n\nThe formula for a gradient update with RMSProp is:\n\n$$r_i=\\rho r_{i-1}+(1-\\rho)\\nabla^2_{\\theta}$$\n\n$$\\theta^{\\prime}=\\theta-\\epsilon \\frac{\\nabla_\\theta}{\\sqrt{r_i+\\delta}}$$\n","metadata":{"id":"_GMNmL_vT1VK"}},{"cell_type":"markdown","source":"****\n**Task 2.4:** Complete the RMSProp gradient update with the update step for `r` and `X`.\n****","metadata":{"id":"y7Z0WoOzbBRV"}},{"cell_type":"code","source":"def RMSprop(X, rho, learning_rate, prev_value, index, Grad=Grad_f):\n    \"\"\"\n    RMSprop optimization step.\n\n    Args:\n        X: Current value of objective function.\n        rhos: Optimization hyperparameter - see formula above.\n        learning_rate: Optimization step size.\n        prev_value: Momentum parameter from previous iteration.\n        index: Not used.\n        Grad: Gradient of quadratic function.\n    \"\"\"\n    delta = 1e-5        # Tiny amount to prevent division by 0\n    gradient = Grad(*X) # Gradient of current values\n    r = 0               # RMSProp parameter\n    r_prev = prev_value # RMSProp parameter from previous iteration\n\n    #############################################################################\n    #                           START OF YOUR CODE                              #\n    #############################################################################\n\n    #############################################################################\n    #                            END OF YOUR CODE                               #\n    #############################################################################\n\n    return X, r\n\n# Optimization settings\nlr = 0.1\nrho = 0.999\n\n# Run optimization\nres_rmsprp = test_optimizer(RMSprop,rho,lr)\n\n# Plot optimization trajectory\nadd_line(*res_rmsprp,fig,*axs,color='y')\n\n# Show figure\nfig","metadata":{"id":"MUBKhp4JOKVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Adaptive Moment Estimation (Adam)\n\nThe idea behind the last optimizer, Adam, is simple. It combines both Momentum and RMSProp in a single optimizer.\n\nThe formula for a gradient update with Adam is:\n\n$$v_i=\\rho_1 v_{i-1}+(1-\\rho_1)\\nabla_{\\theta}$$\n\n$$\\hat{v_i}=\\frac{v_i}{1-\\rho^i_1}$$\n\n$$r_i=\\rho_2 r_{i-1}+(1-\\rho_2)\\nabla^2_{\\theta}$$\n\n$$\\hat{r_i}=\\frac{r_i}{1-\\rho^i_2}$$\n\n$$\\theta^{\\prime}=\\theta-\\epsilon \\frac{\\hat{v_i}}{\\sqrt{\\hat{r_i}+\\delta}}$$\n","metadata":{"id":"GtnmYm4LOKVU"}},{"cell_type":"markdown","source":"****\n**Task 2.5:** Complete the Adam gradient update with the update step for `v`, `v_bc`, `r`, `r_bc` and `X`.\n****","metadata":{"id":"nRonf_62cSjq"}},{"cell_type":"code","source":"def adam(X, rhos, learning_rate, prev_values, index, Grad=Grad_f):\n    \"\"\"\n    Adam optimization step.\n\n    Args:\n        X: Current value of objective function.\n        rhos: Optimization hyperparameter - see formula above.\n        learning_rate: Optimization step size.\n        prev_value: Momentum parameter from previous iteration.\n        index: Optimization step counter.\n        Grad: Gradient of quadratic function.\n    \"\"\"\n\n    delta = 1e-5                 # Tiny amount to prevent division by zero\n    gradient = Grad(*X)          # Gradient of current values\n    rho_v, rho_r = rhos          # Rho values for momentum & rmsProp part of Adam\n    v_prev, r_prev = prev_values # Adam parameters from previous iterations\n\n    v = r = 0                    # Adam paramters for momentum & rmsProp\n    v_bc = r_bc = 0              # Bias corrected adam parameters\n\n    #############################################################################\n    #                           START OF YOUR CODE                              #\n    #############################################################################\n\n    #############################################################################\n    #                            END OF YOUR CODE                               #\n    #############################################################################\n\n    return X,(v,r)\n\n# Optimization settings\nlr = 0.1\nrhos = (0.9, 0.999)\n\n# Run optimization\nres_adam = test_optimizer(adam,rhos,lr)\n\n# Plot optimization trajectory\nadd_line(*res_adam, fig, *axs, color='g')\n\n# Show figure\nfig","metadata":{"id":"rwnpZPCQOKVV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that you have implemented gradient descent with momentum, RMSprop and Adam you can start to play around with the optimizer hyperparameters.\n","metadata":{"id":"tIs9B5VLOKVV"}},{"cell_type":"markdown","source":"****\n**Question 2.6:** What effect does the learning rate have? What is the effect of the $\\rho$ parameter?\n****","metadata":{"id":"tx5rCgwGdXO2"}},{"cell_type":"markdown","source":"# 3 Comparing optimizers in PyTorch\n\nIt is time to test the momentum, RMSProp and Adam optimizers. We will investigate how the optimizer choice influences the convergence speed and final performance on the [MNIST-1D](https://github.com/greydanus/mnist1d) classification task. In this variation of the MNIST dataset, the digits are represented by 1D 40-dimensional tensors.\n\nYou will use the training loop and model definition from the previous labs - let us start by setting them up.","metadata":{"id":"1MClpdNxjNIO"}},{"cell_type":"code","source":"###############################\n### Set up MNIST-1D dataset ###\n###############################\n#Set random seed\ntorch.manual_seed(42)\n\n# Set the batch size for training & testing\nb_size = 100\n\n# Load data\ndata = get_dataset(get_dataset_args(), path='./mnist1d_data.pkl',\n                   download=False, regenerate=True)\n\n# Convert 1D MNIST data to pytorch tensors\ntensors_train = torch.Tensor(data['x']), torch.Tensor(data['y']).long()\ntensors_test = torch.Tensor(data['x_test']), torch.Tensor(data['y_test']).long()\n\n# Create dataloaders from the training and test set for easier iteration over the data\ntrain_loader = DataLoader(TensorDataset(*tensors_train), batch_size=b_size)\ntest_loader = DataLoader(TensorDataset(*tensors_test), batch_size=b_size)\n\n##########################################\n### Define training and test functions ###\n##########################################\n\ndef train(train_loader, net, optimizer, criterion):\n    \"\"\"\n    Trains network for one epoch in batches.\n\n    Args:\n        train_loader: Data loader for training set.\n        net: Neural network model.\n        optimizer: Optimizer (e.g. SGD).\n        criterion: Loss function (e.g. cross-entropy loss).\n    \"\"\"\n\n    avg_loss = 0\n    correct = 0\n    total = 0\n\n    # iterate through batches\n    for i, data in enumerate(train_loader):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # keep track of loss and accuracy\n        avg_loss += loss\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    return avg_loss/len(train_loader), 100 * correct / total\n\ndef test(test_loader, net, criterion):\n    \"\"\"\n    Evaluates network in batches.\n\n    Args:\n        test_loader: Data loader for test set.\n        net: Neural network model.\n        criterion: Loss function (e.g. cross-entropy loss).\n    \"\"\"\n\n    avg_loss = 0\n    correct = 0\n    total = 0\n\n    # Use torch.no_grad to skip gradient calculation, not needed for evaluation\n    with torch.no_grad():\n        # iterate through batches\n        for data in test_loader:\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n\n            # forward pass\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n\n            # keep track of loss and accuracy\n            avg_loss += loss\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return avg_loss/len(test_loader), 100 * correct / total\n\n####################\n### Define model ###\n####################\n\nclass FCNet(nn.Module):\n    \"\"\"\n    Simple fully connected neural network with residual connections in PyTorch.\n    Layers are defined in __init__ and forward pass implemented in forward.\n    \"\"\"\n\n    def __init__(self):\n        super(FCNet, self).__init__()\n\n        self.fc1 = nn.Linear(40, 200)\n        self.fc2 = nn.Linear(200, 200)\n        self.fc3 = nn.Linear(200, 200)\n        self.fc4 = nn.Linear(200, 200)\n        self.fc5 = nn.Linear(200, 200)\n        self.fc6 = nn.Linear(200, 10)\n\n    def forward(self, x):\n        h = F.relu(self.fc1(x))\n        h = h + F.relu(self.fc2(h))\n        h = h + F.relu(self.fc3(h))\n        h = h + F.relu(self.fc4(h))\n        h = h + F.relu(self.fc5(h))\n        return self.fc6(h)\n\n# Print network architecture using torchsummary\nsummary(FCNet(), (40,), device='cpu')","metadata":{"id":"2enVMjXez2Jb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For this part, please import your notebook in Google Colab or download it to work locally.\n\nWe will use [TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) to visualize our results. TensorBoard is a visualization toolkit that provides graphical interface for monitoring and analiyzing deep learning models. The key object for storing data is the `SummaryWriter`. While training your model, you will use methods of the SummaryWriter to log the data that you want to visualize in TensorBoard, as for instance `add_scalar` for scalar values (e.g. loss and accuracy). Let us have a look to a concrete example.\n\n","metadata":{"id":"aeoGeX-XT4zq"}},{"cell_type":"code","source":"#Set random seed\ntorch.manual_seed(42)\n\n# Create a writer to write to Tensorboard\nwriter = SummaryWriter()\n\n# Create instance of Network\nnet = FCNet()\n\n# Create loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(net.parameters(), lr=5e-2)\n\n# Set the number of epochs to for training\nepochs = 100\n\nfor epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n    # Train on data\n    train_loss, train_acc = train(train_loader, net, optimizer, criterion)\n\n    # Test on data\n    test_loss, test_acc = test(test_loader, net, criterion)\n\n    # Log metrics to Tensorboard\n    writer.add_scalars(\"Loss\", {'Train': train_loss, 'Test':test_loss}, epoch)\n    writer.add_scalars('Accuracy', {'Train': train_acc,'Test':test_acc} , epoch)\n\nprint('Finished Training')\n\n#Close the writer\nwriter.flush()\nwriter.close()","metadata":{"id":"dC4tGLeXX_mm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Open Tensorboard and results from the log directory runs/\n%tensorboard --logdir runs/\n\n# For local users only: uncomment the last line, run this cell once and wait for\n# it to time out, run this cell a second time and you should see the board.\n# %tensorboard --logdir runs/ --host localhost","metadata":{"id":"j7NH1zbUYtPi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****\n**Question 3.1:** Can you explain the training curves and the accuracy progressions?\n","metadata":{"id":"UE3StqcxebE4"}},{"cell_type":"markdown","source":"<font color='green'> Write your answer here </font>\n****","metadata":{"id":"FwtZ6jiHfXxO"}},{"cell_type":"markdown","source":"All popular optimization algorithms are readily available in the `torch.optim` package of PyTorch - have a look at the documentation [here](https://pytorch.org/docs/stable/optim.html)] and find how to use momentum, RMSProp and Adam.\n","metadata":{"id":"JCa62JBA8AYH"}},{"cell_type":"markdown","source":"****\n**Task 3.2:** Run the training loop below using `torch.optim` functions for the different optimizers: SGD with momentum, RMSProp and Adam. Then try also different settings.\n****","metadata":{"id":"AyZIayTouCKM"}},{"cell_type":"code","source":"# Create a writer to write to Tensorboard\nwriter = SummaryWriter()\n\n# Create instance of Network\nnet = FCNet()\n\n# Create loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\n\n#############################################################################\n#                          START OF YOUR CODE                               #\n#############################################################################\n\n#############################################################################\n#                            END OF YOUR CODE                               #\n#############################################################################\n\n# Set the number of epochs to for training\nepochs = 100\n\nfor epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n    # Train on data\n    train_loss, train_acc = train(train_loader, net, optimizer, criterion)\n\n    # Test on data\n    test_loss, test_acc = test(test_loader, net, criterion)\n\n    # Write metrics to Tensorboard\n    writer.add_scalars(\"Loss\", {'Train': train_loss, 'Test':test_loss}, epoch)\n    writer.add_scalars('Accuracy', {'Train': train_acc,'Test':test_acc} , epoch)\n\nprint('Finished Training')\n\nwriter.flush()\nwriter.close()","metadata":{"id":"SyZQqMzSScch"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we use again use Tensorboard to visualize our results. Go back to the cell above and hit refresh in the top right corner of TensorBoard to display the results of all subsequent runs. ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAaCAYAAACkVDyJAAABOElEQVRIDe2UsQ3CMBBFMwIjMAIbsBglJRI0dEgwCg2UwAZQQQkNpIgSox/pRx+Ls2OEIgosRXe2z/fy7bOz+yhzXX5ZlzCwfhf4mPRdsZm68rx3bPAxhjndqWK3eunrXCuFxXZGhmkBRmLA0BSifhRYXg4NBMny+aBJBp8ABFX5tYlViPpBIJVV+e0FpAngA+w3P4Z9E4hzYVNVXKhWVXKNzqtvAqkOVhf4/jsYoH4c+yaQZxdSZ8E+Asa2hn+cak2FnQPbbGmqOsSbCtsWjUJ5pqFCM4Ep1wJQvYv+U6c/ZQIRRJV4QULVijm+MiF1yBkEIoBniSIqdssG/Bj3XL4Y1mMssPK4Nu8fVUaBqpSJ39mYsiQggnEuSKqKq+upHgudGUG0rRQy+Bv2D4xWXeo2/7f061v6BP5uhjxw+N1/AAAAAElFTkSuQmCC)","metadata":{"id":"_4eiOQqYLbUe"}},{"cell_type":"markdown","source":"****\n**Question 3.3:** Which optimizer converges faster? Did they all reach the same final accuracy? Did you have to use different learning rates for different optimizers?\n****","metadata":{"id":"BcXTrkpScwFp"}},{"cell_type":"markdown","source":"**That's all for this lab, see you in the next one!**","metadata":{"id":"V36bVnxeBBwr"}},{"cell_type":"markdown","source":"**Feedback Form:** please fill in the following form to provide feedback https://forms.office.com/e/KH7vWKMkQ8","metadata":{}}]}